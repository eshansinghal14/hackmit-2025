You are Agent 2 of 5, a specialized research expert analyzing "linear algebra". You are part of a distributed team where each agent analyzes a subset of research data to generate comprehensive knowledge nodes.

# Agent 2 Research Context

## Assignment
You are Agent 2 of 5 specialized research agents analyzing: "linear algebra"

## Your Data Subset
- Agent ID: 2/5
- Sites Assigned: 10
- Total Sites Across All Agents: 50
- Your Coverage: Sites 11 to 20

## Your Research Sources

### Source 11: Linear Algebra

**Content:**
If you're seeing this message, it means we're having trouble loading external resources on our website.

If you're behind a web filter, please make sure that the domains \*.kastatic.org and \*.kasandbox.org are unblocked.

## Oops. Something went wrong. Please try again.

Uh oh, it looks like we ran into an error. You need to [refresh](https://www.khanacademy.org/www.khanacademy.org). If this problem persists, [tell us](https://www.khanacademy.org/reportissue?type=Defect).


---

### Source 12: What Is Linear Algebra?

**Content:**
# What Is Linear Algebra?

Written by Coursera Staff • Updated on May 6, 2025

Learn what linear algebra is, its common concepts, and its use in machine learning, as well as careers you can pursue that use linear algebra.

Linear algebra combines multivariate calculus, differential equations, and probability into a widely applicable mathematical theory and system that undergirds many technologies in our lives. At its core, linear algebra studies vectors and linear functions to solve systems of linear equations that contain multiple variables. It focuses on calculating vectors, which are points in space with magnitude and direction, and matrices, which are tables of numbers.

While linear algebra is not a prerequisite for starting in machine learning, its concepts become foundational for a deeper understanding of the algorithms used in machine learning. It can help when you encounter deep learning concepts so that you can make informed decisions when developing a new machine learning system.

This article takes a deeper look at concepts in linear algebra, its uses, its users, how it's employed in machine learning, and how you can study it.

## Concepts in linear algebra

Linear algebra contains many applicable concepts. Here are some of the concepts in linear algebra that are also useful in machine learning:

- Vectors and vector spaces

- Systems of linear equations

- Matrices

- Eigenvalues and [Eigenvectors](https://www.coursera.org/articles/eigenvector-centrality)


Let’s take a closer look at each concept.

### What is linear algebra in simple terms?

Linear algebra is a branch of mathematics that analyzes vectors, matrices, and linear transformations. One of its main concerns is finding solutions using vectors to represent something in physical space. Solutions are called vector spaces, and you can add and multiply vectors to find these solutions.

### Vectors and vector spaces

A vector is a quantity that has magnitude and direction. In linear algebra, you can add and multiply vectors by following the vector addition and multiplication rules. Linear algebra deals with many kinds of vectors:

- Power series

- Polynomials

- Numbers

- n-vectors

- Functions with a specific domain

- 2nd order polynomials


A vector space is a set that adds and multiplies the properties of a vector. Vector spaces have 10 axioms that vectors follow when adding and multiplying.

### Systems of linear equations

Linear algebra examines linear functions, which have vectors as both the input and the output. A matrix is an example of a linear function when it is multiplied by transforming a vector into another vector. A system of linear equations changes to a matrix equation through an augmented matrix in a process called Gaussian elimination. To solve a system of linear equations, you use reduced row echelon form, which simplifies the system of equations into a matrix, getting the linear equation into a solvable form.

### Matrices

A matrix is the result of a s... [Content truncated for context window]


---

### Source 13: Linear Algebra Done Wrong

**Content:**
| | | |
| --- | --- | --- |
| | | | |
| --- | --- |
| [Math. Department home page](http://www.math.brown.edu) | [back\ to my home page](https://www.math.brown.edu/streil/index.html) |

### A textbook for an honors linear algebra course (updated Sept. 4, 2017):

## Linear Algebra Done Wrong.

### by Sergei Treil

### From the Introduction:

The
title of the book sounds a bit mysterious. Why should anyone read this
book if it presents the subject in a wrong way? What is particularly
done "wrong" in the book?

Before
answering these questions, let me first describe the target audience of
this text. This book appeared as lecture notes for the course "Honors
Linear Algebra". It supposed to be a _first_ linear
algebra course for mathematically
advanced students. It is intended for a student who, while not yet very
familiar with abstract reasoning, is willing to study more rigorous
mathematics that is presented in a "cookbook style" calculus type
course. Besides being a first course in linear algebra it is also
supposed to be a first course introducing a student to _rigorous_
proof, formal definitions---in short, to the style of modern
theoretical (abstract) mathematics.

The target audience explains the very specific blend of elementary
ideas and concrete examples, which are usually presented in
introductory linear algebra texts with more abstract definitions and
constructions typical for advanced books.

Another specific of the book is that it is not written by or for an
algebraist. So, I tried to emphasize the topics that are important for
analysis, geometry, probability, etc., and did not include some
traditional topics. For example, I am only considering vector spaces
over the fields of real or complex numbers. Linear spaces over other
fields are not considered at all, since I feel time required to
introduce and explain abstract fields would be better spent on some
more classical topics, which will be required in other disciplines. And
later, when the students study general fields in an abstract algebra
course they will understand that many of the constructions studied in
this book will also work for general fields.

Also, I treat only finite-dimensional spaces in this book and a basis
always means a finite basis. The reason is that it is impossible to say
something non-trivial about infinite-dimensional spaces without
introducing convergence, norms, completeness etc., i.e. the basics of
functional analysis. And this is definitely a subject for a separate
course (text). So, I do not consider infinite Hamel bases here: they
are not needed in most applications to analysis and geometry, and I
feel they belong in an abstract algebra course.

### Terms of use:

 [![Creative Commons License](http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png)](http://creativecommons.org/licenses/by-nc-nd/3.0/)

This book  is licensed under a [Creative\
Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License](http://creativecommons.org/licenses/by-nc-nd/3.0/).
... [Content truncated for context window]


---

### Source 14: FCLA What is Linear Algebra?

**Content:**
[Skip to main content](https://runestone.academy/ns/books/published/fcla/section-WILA.html#content)

\\(\\newcommand{\\orderof}\[1\]{\\sim #1}
\\newcommand{\\Z}{\\mathbb{Z}}
\\newcommand{\\reals}{\\mathbb{R}}
\\newcommand{\\real}\[1\]{\\mathbb{R}^{#1}}
\\newcommand{\\complexes}{\\mathbb{C}}
\\newcommand{\\complex}\[1\]{\\mathbb{C}^{#1}}
\\newcommand{\\conjugate}\[1\]{\\overline{#1}}
\\newcommand{\\modulus}\[1\]{\\left\\lvert#1\\right\\rvert}
\\newcommand{\\zerovector}{\\vect{0}}
\\newcommand{\\zeromatrix}{\\mathcal{O}}
\\newcommand{\\innerproduct}\[2\]{\\left\\langle#1,\\,#2\\right\\rangle}
\\newcommand{\\norm}\[1\]{\\left\\lVert#1\\right\\rVert}
\\newcommand{\\dimension}\[1\]{\\dim\\left(#1\\right)}
\\newcommand{\\nullity}\[1\]{n\\left(#1\\right)}
\\newcommand{\\rank}\[1\]{r\\left(#1\\right)}
\\newcommand{\\ds}{\\oplus}
\\newcommand{\\detname}\[1\]{\\det\\left(#1\\right)}
\\newcommand{\\detbars}\[1\]{\\left\\lvert#1\\right\\rvert}
\\newcommand{\\trace}\[1\]{t\\left(#1\\right)}
\\newcommand{\\sr}\[1\]{#1^{1/2}}
\\newcommand{\\spn}\[1\]{\\left\\langle#1\\right\\rangle}
\\newcommand{\\nsp}\[1\]{\\mathcal{N}\\!\\left(#1\\right)}
\\newcommand{\\csp}\[1\]{\\mathcal{C}\\!\\left(#1\\right)}
\\newcommand{\\rsp}\[1\]{\\mathcal{R}\\!\\left(#1\\right)}
\\newcommand{\\lns}\[1\]{\\mathcal{L}\\!\\left(#1\\right)}
\\newcommand{\\per}\[1\]{#1^\\perp}
\\newcommand{\\augmented}\[2\]{\\left\\lbrack\\left.#1\\,\\right\\rvert\\,#2\\right\\rbrack}
\\newcommand{\\linearsystem}\[2\]{\\mathcal{LS}\\!\\left(#1,\\,#2\\right)}
\\newcommand{\\homosystem}\[1\]{\\linearsystem{#1}{\\zerovector}}
\\newcommand{\\rowopswap}\[2\]{R\_{#1}\\leftrightarrow R\_{#2}}
\\newcommand{\\rowopmult}\[2\]{#1R\_{#2}}
\\newcommand{\\rowopadd}\[3\]{#1R\_{#2}+R\_{#3}}
\\newcommand{\\leading}\[1\]{\\boxed{#1}}
\\newcommand{\\rref}{\\xrightarrow{\\text{RREF}}}
\\newcommand{\\elemswap}\[2\]{E\_{#1,#2}}
\\newcommand{\\elemmult}\[2\]{E\_{#2}\\left(#1\\right)}
\\newcommand{\\elemadd}\[3\]{E\_{#2,#3}\\left(#1\\right)}
\\newcommand{\\scalarlist}\[2\]{{#1}\_{1},\\,{#1}\_{2},\\,{#1}\_{3},\\,\\ldots,\\,{#1}\_{#2}}
\\newcommand{\\vect}\[1\]{\\mathbf{#1}}
\\newcommand{\\colvector}\[1\]{\\begin{bmatrix}#1\\end{bmatrix}}
\\newcommand{\\vectorcomponents}\[2\]{\\colvector{#1\_{1}\\\#1\_{2}\\\#1\_{3}\\\\\vdots\\\#1\_{#2}}}
\\newcommand{\\vectorlist}\[2\]{\\vect{#1}\_{1},\\,\\vect{#1}\_{2},\\,\\vect{#1}\_{3},\\,\\ldots,\\,\\vect{#1}\_{#2}}
\\newcommand{\\vectorentry}\[2\]{\\left\\lbrack#1\\right\\rbrack\_{#2}}
\\newcommand{\\matrixentry}\[2\]{\\left\\lbrack#1\\right\\rbrack\_{#2}}
\\newcommand{\\lincombo}\[3\]{#1\_{1}\\vect{#2}\_{1}+#1\_{2}\\vect{#2}\_{2}+#1\_{3}\\vect{#2}\_{3}+\\cdots +#1\_{#3}\\vect{#2}\_{#3}}
\\newcommand{\\matrixcolumns}\[2\]{\\left\\lbrack\\vect{#1}\_{1}\|\\vect{#1}\_{2}\|\\vect{#1}\_{3}\|\\ldots\|\\vect{#1}\_{#2}\\right\\rbrack}
\\newcommand{\\transpose}\[1\]{#1^{t}}
\\newcommand{\\inverse}\[1\]{#1^{-1}}
\\newcommand{\\submatrix}\[3\]{#1\\left(#2\|#3\\right)}
\\newcommand{\\adj}\[1\]{\\transpos... [Content truncated for context window]


---

### Source 15: University of California, Santa Barbara, Department of Mathematics

**Content:**
- [UCSB Math Home Page](http://math.ucsb.edu/)

- [Graduate Information](http://math.ucsb.edu/grad/index.php)

- [Undergraduate Information](http://math.ucsb.edu/ugrad/index.php)

- [Colloquium and Seminars](javascript:toggle('mainmenu','colloqmenu'))
[Colloquium](http://math.ucsb.edu/calendar/cal_cat.php?op=cat&id=24&catview=0)
[Seminars](http://math.ucsb.edu/department/seminars.php)
[Distinguished Lectures](http://math.ucsb.edu/~drm/distinguished-lecturers)
[This Week in Math](http://math.ucsb.edu/calendar/cal_week?op=week&catview=0)
 - [History and Search](http://math.ucsb.edu/calendar/cal_cat.php?op=cats&catview=0)

- [Current Recruitment](http://math.ucsb.edu/department/recruit.php)

- [People](javascript:toggle('mainmenu2','peoplemenu'))


[Faculty](http://math.ucsb.edu/department/faculty.php)
[Visiting Faculty](http://math.ucsb.edu/department/visiting.php)
[Affiliated Faculty](http://math.ucsb.edu/department/affiliated.php)
[Emeriti](http://math.ucsb.edu/department/emeriti.php)
[Graduate Students](http://math.ucsb.edu/department/gradstudents.php)
[Staff](http://math.ucsb.edu/department/staff.php)
[Alumni](http://math.ucsb.edu/department/alumni.php)
- [Faculty Awards](http://math.ucsb.edu/department/awards.php)

- [Mathematics Centers](javascript:toggle('mainmenu3','mathmenu'))
[Center for Mathematical\
\
   Inquiry](http://web.math.ucsb.edu/department/cmi)
[Computational Science\
\
   and Engineering](http://www.cse.ucsb.edu/)
[Center for Complex &\
\
   Nonlinear Science](http://repositories.cdlib.org/cnls/)
[Complex Fluids Design\
\
   Consortium](http://www.mrl.ucsb.edu/cfdc/)
[Center for Control, Dynamical\
\
   Systems and Computation](http://www.ece.ucsb.edu/ccdc/)
[California Nanosystems\
\
    Institute](http://www.cnsi.ucsb.edu/)
 - [UCSB Math Circle](http://www.math.ucsb.edu/mathcircle/)

- [Preprint Series](http://math.ucsb.edu/preprints)

- [Research](http://math.ucsb.edu/department/research.php)

- [Other Information](javascript:toggle('mainmenu5','othermenu'))
[WebMail](https://mail.math.ucsb.edu/webmail)
[Math Personnel Info](http://math.ucsb.edu/htgtd/index.php)
[WebWork](http://webwork.math.ucsb.edu)
[Our Location](http://math.ucsb.edu/department/map.php)
[Computing Resources](http://math.ucsb.edu/department/computing.php)
[Math Sci Net](http://www.ams.org/mathscinet)
 - [WWW Links](http://math.ucsb.edu/department/links.php)

- [Giving to Mathematics](http://math.ucsb.edu/department/donate.php)

[Follow us: ![](http://web.math.ucsb.edu/images/20px-facebook-favicon.jpg)](http://www.facebook.com/pages/Mathematics-Dept-UC-Santa-Barbara/388265455241?ref=mf)

Department of Mathematics

South Hall, Room 6607

University of California

Santa Barbara, CA 93106

[Phone Numbers](http://math.ucsb.edu/department/staff.php)

Fax (805) 893-2385

Email: [www@math.ucsb.edu](mailto:www@math.ucsb.edu)

Office Hours: Mon-Fri 9-12, 1-4

Copyright (c) 2011 the Regents

of the University of California,

All Rights reserved. [Terms of Use](http:... [Content truncated for context window]


---

### Source 16: Overview

**Content:**
[Skip to main content](https://services.math.duke.edu/~jdr/ila/overview.html#content)

##### The Subject of This Textbook

Before starting with the content of the text, we first ask the basic question: what _is_ linear algebra?

- _Linear:_ having to do with lines, planes, etc.
- _Algebra:_ solving equations involving unknowns.

The name of the textbook highlights an important theme: the synthesis between algebra and geometry. It will be very important to us to understand systems of linear equations both _algebraically_ (writing equations for their solutions) and _geometrically_ (drawing pictures and visualizing).

**Remark**

The term “algebra” was coined by the 9th century mathematician Abu Ja’far Muhammad ibn Musa al-Khwarizmi. It comes from the Arabic word _al-jebr_, meaning reunion of broken parts.

At the simplest level, solving a system of linear equations is not very hard. You probably learned in high school how to solve a system like

Ax+3y−z=42x−y+3z=17y−4z=−3.

However, in real life one usually has to be more clever.

- Engineers need to solve many, many equations in many, many variables. Here is a tiny example:
BEDEC3x1+4x2+10x3+19x4−2x5−3x6=1417x1+2x2−13x3−7x4+21x5+8x6=2567−x1+9x2+32x3+x4+14x5+27x6=2612x1+4x2+10x3+11x4+2x5+x6=−15.

- Often it is enough to know some information about the set of solutions, without having to solve the equations in the first place. For instance, does there exist a solution? What does the solution set look like geometrically? Is there still a solution if we change the 26 to a 27?
- Sometimes the coefficients also contain parameters, like the _eigenvalue equation_
A(7−λ)x+y+3z=0−3x+(2−λ)y−3z=0−3x−2y+(−1−λ)z=0.

- In data modeling, a system of equations generally does not actually have a solution. In that case, what is the best approximate solution?

Accordingly, this text is organized into three main sections.

1. Solve the matrix equation Ax=b (chapters 2–4).

 - Solve systems of linear equations using matrices, row reduction, and inverses.
 - Analyze systems of linear equations geometrically using the geometry of solution sets and linear transformations.
2. Solve the matrix equation Ax=λx (chapters 5–6).

 - Solve eigenvalue problems using the characteristic polynomial.
 - Understand the geometry of matrices using similarity, eigenvalues, diagonalization, and complex numbers.
3. Approximately solve the matrix equation Ax=b (chapter 7).

 - Find best-fit solutions to systems of linear equations that have no actual solution using least-squares approximations.
 - Study the geometry of closest vectors and orthogonal projections.

This text is roughly half computational and half conceptual in nature. The main goal is to present a library of linear algebra tools, and more importantly, to teach a conceptual framework for understanding which tools should be applied in a given context.

If Matlab can find the answer faster than you can, then your question is just an algorithm: this is not real problem solving.

T... [Content truncated for context window]


---

### Source 17: Mathonline

**Content:**
![linearalgebraheader.png](http://mathonline.wdfiles.com/local--files/admin%3Aimages/linearalgebraheader.png)

![Screen%20Shot%202014-09-16%20at%202.55.17%20PM.png](http://mathonline.wdfiles.com/local--files/linear-algebra/Screen%20Shot%202014-09-16%20at%202.55.17%20PM.png)

# Linear Algebra Topics

* * *

## 1\. Systems of Linear Equations and Matrices

###### 1.1. Systems of Linear Equations

- [Linear Equations](http://mathonline.wikidot.com/linear-equations)
- [Systems of Linear Equations](http://mathonline.wikidot.com/systems-of-linear-equations)
- [Solutions to Systems of 2-Variables and 3-Variables](http://mathonline.wikidot.com/solutions-to-systems-of-2-variables-and-3-variables)
- [Homogenous Linear Systems](http://mathonline.wikidot.com/homogenous-linear-systems)

###### 1.2. Introduction to Matrices and Elementary Row Operations

- [Matrices and Elementary Row Operations](http://mathonline.wikidot.com/matrices-and-elementary-row-operations)
- [Row Echelon Form of a Matrix (REF)](http://mathonline.wikidot.com/row-echelon-form-of-a-matrix-ref)
- [Gaussian Elimination and Back Substitution](http://mathonline.wikidot.com/gaussian-elimination-and-back-substitution)
- [Reduced Row Echelon Form of a Matrix (RREF)](http://mathonline.wikidot.com/reduced-row-echelon-form-of-a-matrix-rref)
- [Gauss-Jordan Elimination](http://mathonline.wikidot.com/gauss-jordan-elimination)

###### 1.3. Operations on Matrices, and Special Types of Matrices

- [Matrix Addition and Subtraction](http://mathonline.wikidot.com/matrix-addition-and-subtraction)
- [Scalar Multiples of Matrices](http://mathonline.wikidot.com/scalar-multiples-of-matrices)
- [The Transpose of a Matrix](http://mathonline.wikidot.com/the-transpose-of-a-matrix)
- [The Trace of a Square Matrix](http://mathonline.wikidot.com/the-trace-of-a-square-matrix)
- [Matrix Multiplication](http://mathonline.wikidot.com/matrix-multiplication)
- [Zero Matrices](http://mathonline.wikidot.com/zero-matrices)
- [Diagonal Matrices](http://mathonline.wikidot.com/diagonal-matrices)
- [Triangular Matrices](http://mathonline.wikidot.com/triangular-matrices)
- [Symmetric Matrices](http://mathonline.wikidot.com/symmetric-matrices)
- [Identity Matrices](http://mathonline.wikidot.com/identity-matrices)
- [Inverse of a Matrix](http://mathonline.wikidot.com/inverse-of-a-matrix)
- [Inverse of Diagonal Matrices](http://mathonline.wikidot.com/inverse-of-diagonal-matrices)
- [Powers of a Matrix](http://mathonline.wikidot.com/powers-of-a-matrix)
- [Matrix Polynomials](http://mathonline.wikidot.com/matrix-polynomials)
- [Elementary Matrices](http://mathonline.wikidot.com/elementary-matrices)
- [Finding a Matrix's Inverse with Elementary Matrices](http://mathonline.wikidot.com/finding-a-matrix-s-inverse-with-elementary-matrices)
- [Finding a Matrix's Inverse with Row Operations](http://mathonline.wikidot.com/finding-a-matrix-s-inverse-with-row-operations)

* * *

## 2\. Determinants

###### 2.1. The Determinant of Square Matrices... [Content truncated for context window]


---

### Source 18: Linear algebra review

**Content:**
**Next:** [Matrix decompositions](https://nlp.stanford.edu/matrix-decompositions-1.html) **Up:** [Matrix decompositions and latent](https://nlp.stanford.edu/matrix-decompositions-and-latent-semantic-indexing-1.html) **Previous:** [Matrix decompositions and latent](https://nlp.stanford.edu/matrix-decompositions-and-latent-semantic-indexing-1.html) **[Contents](https://nlp.stanford.edu/contents-1.html)** **[Index](https://nlp.stanford.edu/index-1.html)**

# Linear algebra review

We briefly review some necessary background in linear algebra. Let be an
matrix with real-valued entries; for a term-document matrix, all entries are in fact non-negative.

The _rank_ of a matrix is the number of linearly independent rows (or columns) in it; thus,
. A square matrix all of whose off-diagonal entries are zero is called a _diagonal matrix_; its rank is equal to the number of non-zero diagonal entries. If all diagonal entries of such a diagonal matrix are , it is called the identity matrix of dimension and represented by .

For a square
matrix and a vector that is not all zeros, the values of satisfying

| |
| --- |
| (213) |

are called the
_eigenvalues_
of
. The -vector satisfying Equation [213](https://nlp.stanford.edu/nlp.stanford.edu#eqn:right-eigen) for an eigenvalue is the corresponding _right eigenvector_. The eigenvector corresponding to the eigenvalue of largest magnitude is called the _principal eigenvector._ In a similar fashion, the _left eigenvectors_ of are the -vectors such that

| |
| --- |
| (214) |

The number of non-zero eigenvalues of is at most
.

The eigenvalues of a matrix are found by solving the
_characteristic equation_, which is obtained by
rewriting Equation [213](https://nlp.stanford.edu/nlp.stanford.edu#eqn:right-eigen) in the form
. The eigenvalues of are then the solutions of
, where denotes the determinant of a square matrix .
The equation
is an th order polynomial equation in and can have at most roots, which are the
eigenvalues of . These eigenvalues can in general be complex, even if all entries of are real.

We now examine some further properties of eigenvalues and eigenvectors, to set up the central idea of singular value decompositions in Section [18.2](https://nlp.stanford.edu/term-document-matrices-and-singular-value-decompositions-1.html#sec:svd) below. First, we look at the relationship between matrix-vector multiplication and eigenvalues.

**Worked example.**
Consider the matrix

| |
| --- |
| (215) |

Clearly the matrix has rank 3, and has 3 non-zero eigenvalues and , with the three corresponding eigenvectors

| |
| --- |
| (216) |

For each of the eigenvectors, multiplication by acts as if we were multiplying the eigenvector by a multiple of the identity matrix; the multiple is different for each eigenvector. Now, consider an arbitrary vector, such as
We can always express as a linear combination of the three eigenvectors of ; in the current example we have

| |
| --- |
| (217) |

Suppose we multiply by :

| |
| -... [Content truncated for context window]


---

### Source 19: Elementary linear algebra

**Content:**
# Elementary linear algebra

Sep 17, 20153 likes1,931 viewsAI-enhanced description

[![Ayupratiwi Geophysics](https://cdn.slidesharecdn.com/profile-photo-ayupratiwigeophysics-48x48.jpg?cb=1523537863)\
Ayupratiwi Geophysics](https://www.slideshare.net/ayupratiwigeophysics)

This document is a textbook on elementary linear algebra. Chapter 1 introduces linear equations in n unknowns and systems of m linear equations in n unknowns. It discusses solving linear equations and systems for solutions. Geometrically, solving systems of linear equations in two or three unknowns corresponds to finding the common point of intersection of lines or planes. Examples are provided to illustrate solving single equations, systems of equations, and finding polynomials that satisfy given points.

Read more

1 of 201

Download nowDownloaded 25 times

![ELEMENTARY LINEAR ALGEBRA K. R. MATTHEWS DEPARTMENT OF MATHEMATICS UNIVERSITY OF QUEENSLAND Corrected Version, 27th April 2013 Comments to the author at keithmatt@gmail.com ](https://image.slidesharecdn.com/elementarylinearalgebra-150917035140-lva1-app6891/75/Elementary-linear-algebra-1-2048.jpg)

![Contents 1 LINEAR EQUATIONS 1 1.1 Introduction to linear equations . . . . . . . . . . . . . . . . . 1 1.2 Solving linear equations . . . . . . . . . . . . . . . . . . . . . 5 1.3 The Gauss–Jordan algorithm . . . . . . . . . . . . . . . . . . 8 1.4 Systematic solution of linear systems. . . . . . . . . . . . . . 9 1.5 Homogeneous systems . . . . . . . . . . . . . . . . . . . . . . 16 1.6 PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2 MATRICES 23 2.1 Matrix arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.2 Linear transformations . . . . . . . . . . . . . . . . . . . . . . 27 2.3 Recurrence relations . . . . . . . . . . . . . . . . . . . . . . . 31 2.4 PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.5 Non–singular matrices . . . . . . . . . . . . . . . . . . . . . . 36 2.6 Least squares solution of equations . . . . . . . . . . . . . . . 47 2.7 PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3 SUBSPACES 55 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 3.2 Subspaces of Fn . . . . . . . . . . . . . . . . . . . . . . . . . 55 3.3 Linear dependence . . . . . . . . . . . . . . . . . . . . . . . . 58 3.4 Basis of a subspace . . . . . . . . . . . . . . . . . . . . . . . . 61 3.5 Rank and nullity of a matrix . . . . . . . . . . . . . . . . . . 63 3.6 PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4 DETERMINANTS 71 4.1 PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 i ](https://image.slidesharecdn.com/elementarylinearalgebra-150917035140-lva1-app6891/75/Elementary-linear-algebra-2-2048.jpg)

![5 COMPLEX NUMBERS 89 5.1 Constructing the complex numbers . . . . . . . . . . . . . . . 89 5.2 Calculating with complex numbers . . . . . . . . . . . . . . . 91 5.3 Geometric representation of C . . . . . ... [Content truncated for context window]


---

### Source 20: What is Linear Algebra actually used for? How did it start out?

**Content:**

 What is Linear Algebra actually used for? How did it start out? 
 Author: DeepRNA 
 Time Posted (UTC): 2021-02-11 00:47:22+00:00 
 Score: 278 
 


 
 Link: https://www.reddit.com/r/math/comments/lh8pm7/what_is_linear_algebra_actually_used_for_how_did/ 
 


 
 I dont think linear algebra started out as pure mathematics then found use cases. Imagine you are an early mathematician, what problems were you trying to solve? How did linear algebra help? How does it help in todays world? (If you can, please use engineering examples). Im trying to write down reasons for students to even want to learn linear algebra. But not knowing enough about it I am struggling compiling information on it. 
 


 
 Comments 
 


 
 
 Comment by: KingOfTheEigenvalues
 | Posted (UTC): 2021-02-11
 | Score: 343
 
 A much harder question is "what is linear algebra NOT used for?" It comes up in pretty much every branch of modern mathematics and extends to applications in pretty much every STEM field. 


 
 
 Comment by: hubryan
 | Posted (UTC): 2021-02-11
 | Score: 122
 
 every area of math is within 3 concepts away from linear algebra 


 
 
 Comment by: punaisetpimpulat
 | Posted (UTC): 2021-02-11
 | Score: 3
 
 I’ve heard that every mathematical operation can be reduced to addition. That’s certainly true for multiplying and exponents, but perhaps it can also work with more complicated concepts too. If that’s the case, we could also say that everything is just few steps away from addition. 


 
 
 Comment by: [deleted]
 | Posted (UTC): 2021-02-11
 | Score: 23
 
 I believe addition and multiplication can be fundamentally different, depending on the context. 


 
 
 Comment by: DrSeafood
 | Posted (UTC): 2021-02-11
 | Score: 13
 
 Yeah. Like ... How about function composition? That doesn't resemble "addition" in any reasonable way, as far as I can tell. Or commutator \[a,b\] = ab - ba? That's not even associative. Edit: ooh. They probably meant that subtraction is adding negatives, multiplication is repeated addition, division is inverse multiplication, exponents are repeated multiplication... All basic arithmetic is connected to addition in some way. That makes sense. 

 

 
 
 Comment by: ElectricalIons
 | Posted (UTC): 2021-02-12
 | Score: 2
 
 Yeah, the simplest evidence being that the additive identity and multiplicative identity are in general not the same. Addition and multiplication don't seem to interact much in rings. 

 
 

 
 
 Comment by: alimaze-9825
 | Posted (UTC): 2021-02-11
 | Score: 2
 
 a vector like [a, b] can be written as a + b so I'm inclined to believe it can be extended to matrices of any size. 

 

 
 
 Comment by: [deleted]
 | Posted (UTC): 2021-02-11
 | Score: 1
 
 [deleted] 


 
 
 Comment by: SV-97
 | Posted (UTC): 2021-02-11
 | Score: 4
 
 e = lim\_{n to infty} (1+1/n)\^n - you can write the power as repeated multiplication as addition and use a power series for 1/n to reduce all you have to do to addition :) Not saying it's true that you can ... [Content truncated for context window]


---



## Your Mission as Agent 2:
1. Analyze ONLY the research sources assigned to you above
2. Extract 3-5 key knowledge nodes from YOUR assigned sources
3. Each node should be a distinct concept, technique, or methodology
4. Base nodes strictly on the content provided in your sources
5. Focus on the most important and well-supported concepts
6. Ensure nodes are specific and actionable
7. Include both foundational and advanced concepts if present

## Agent Coordination:
- You are Agent 2 of 5 total agents
- Each agent analyzes different sources to avoid duplication
- Your findings will be combined with other agents' results
- Focus on quality over quantity from your assigned sources

## Output Format:
Generate your knowledge nodes in this exact format:

**Agent 2 Knowledge Nodes for: Linear Algebra**

1. [Node Name]
2. [Node Name]
3. [Node Name]
4. [Node Name]
5. [Node Name]

**Source Summary:**
- Sources Analyzed: 10
- Agent Coverage: 10 of 50 total sources

Generate your specialized knowledge nodes now based strictly on your assigned research sources above.